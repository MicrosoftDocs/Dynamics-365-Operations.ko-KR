---
title: 데이터 가져오기 및 내보내기 작업 개요
description: 데이터 관리 작업 공간을 사용하여 데이터 가져오기 및 내보내기 작업을 만들고 관리합니다.
author: peakerbl
ms.date: 10/21/2021
ms.topic: overview
ms.prod: ''
ms.technology: ''
audience: Application user
ms.reviewer: sericks
ms.search.region: Global
ms.author: peakerbl
ms.search.validFrom: 2016-02-28
ms.dyn365.ops.version: AX 7.0.0
ms.openlocfilehash: e63daad6f206500bfa21c28635648c717f5bbdde
ms.sourcegitcommit: 3a7f1fe72ac08e62dda1045e0fb97f7174b69a25
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/31/2022
ms.locfileid: "8460820"
---
# <a name="data-import-and-export-jobs-overview"></a>데이터 가져오기 및 내보내기 작업 개요

[!include [banner](../includes/banner.md)]


[!INCLUDE [PEAP](../../../includes/peap-1.md)]

데이터 가져오기 및 내보내기 작업을 만들고 관리하려면 **데이터 관리** 작업 영역을 사용합니다. 기본적으로 데이터 가져오기 및 내보내기 프로세스는 대상 데이터베이스의 각 엔터티에 대한 준비 테이블을 만듭니다. 준비 테이블을 사용하면 데이터를 이동하기 전에 확인, 정리 또는 변환할 수 있습니다.

> [!NOTE]
> 이번에는 사용자가 [데이터 엔터티](data-entities.md)에 익숙하다고 가정합니다.

## <a name="data-importexport-process"></a>데이터 가져오기/내보내기 프로세스
다음은 데이터를 가져오거나 내보내는 단계입니다.

1. 다음 작업을 완료하는 가져오기 또는 내보내기 작업을 생성합니다.

    - 프로젝트 범주를 정의합니다.
    - 가져오거나 내보낼 엔터티를 식별합니다.
    - 작업의 데이터 형식을 설정합니다.
    - 논리적 그룹에서 합리적인 순서로 처리되도록 엔터티를 시퀀싱합니다.
    - 스테이징 테이블을 사용할지 여부를 결정합니다.

2. 원본 데이터와 대상 데이터가 올바르게 매핑되었는지 확인합니다.
3. 가져오기 또는 내보내기 작업의 보안을 확인하십시오.
4. 가져오기 또는 내보내기 작업을 실행합니다.
5. 작업 기록을 검토하여 작업이 예상대로 실행되었는지 확인합니다.
6. 준비 테이블을 정리합니다.

이 항목의 나머지 섹션에서는 프로세스의 각 단계에 대한 자세한 내용을 제공합니다.

> [!NOTE]
> 최신 진행 상황을 보기 위해 데이터 가져오기/내보내기 양식을 새로 고치려면 양식 새로 고침 아이콘을 사용하십시오. 브라우저 수준 새로 고침은 일괄적으로 실행되지 않는 가져오기/내보내기 작업을 방해하므로 권장되지 않습니다.

## <a name="create-an-import-or-export-job"></a>가져오기 또는 내보내기 작업 만들기
데이터 가져오기 또는 내보내기 작업은 한 번 또는 여러 번 실행할 수 있습니다.

### <a name="define-the-project-category"></a>프로젝트 카테고리 정의
가져오기 또는 내보내기 작업에 적절한 프로젝트 범주를 선택하는 데 시간을 할애하는 것이 좋습니다. 프로젝트 범주는 관련 작업을 관리하는 데 도움이 될 수 있습니다.

### <a name="identify-the-entities-to-import-or-export"></a>가져오거나 내보낼 엔티티 식별
가져오기 또는 내보내기 작업에 특정 엔터티를 추가하거나 적용할 템플릿을 선택할 수 있습니다. 템플릿은 엔터티 목록으로 작업을 채웁니다. 작업 이름을 지정하고 작업을 저장한 후에 **템플릿 적용** 옵션을 사용할 수 있습니다.

### <a name="set-the-data-format-for-the-job"></a>작업의 데이터 형식 설정
엔터티를 선택할 때 내보내거나 가져올 데이터 형식을 선택해야 합니다. **데이터 소스 설정** 타일을 사용하여 형식을 정의합니다. 소스 데이터 형식은 **유형**, **파일 형식**, **행 구분 기호** 및 **열 구분 기호** 의 조합입니다. 다른 속성도 있지만 이것들은 이해해야 할 핵심 속성입니다. 다음 표에는 유효한 조합이 나열되어 있습니다.

| 파일 형식            | 행/열 구분 기호                       | XML 스타일                 |
|------------------------|--------------------------------------------|---------------------------|
| 뛰어나다                  | 뛰어나다                                      | \-없음                     |
| XML                    | \-없음                                      | XML-요소 XML-속성 |
| 구분된 고정 너비 | 쉼표, 세미콜론, 탭, 세로 막대, 콜론 | \-없음                     |

> [!NOTE]
> **파일 형식** 옵션이 **구분** 으로 설정된 경우 **행 구분 기호**, **열 구분 기호** 및 **텍스트 한정자** 에 대해 올바른 값을 선택하는 것이 중요합니다. 가져오기 및 내보내기 중에 오류가 발생할 수 있으므로 데이터에 구분 기호 또는 한정자로 사용되는 문자가 포함되어 있지 않은지 확인하십시오.

### <a name="sequence-the-entities"></a>엔티티 시퀀싱
엔터티는 데이터 템플릿이나 가져오기 및 내보내기 작업에서 순서를 지정할 수 있습니다. 둘 이상의 데이터 엔터티가 포함된 작업을 실행할 때 데이터 엔터티의 순서가 올바른지 확인해야 합니다. 엔터티 간의 함수적 종속성을 해결할 수 있도록 기본적으로 엔터티의 순서를 지정합니다. 엔터티에 함수적 종속성이 없는 경우 병렬 가져오기 또는 내보내기를 예약할 수 있습니다.

#### <a name="execution-units-levels-and-sequences"></a>실행 단위, 수준 및 시퀀스
실행 단위, 실행 단위의 수준 및 엔터티 시퀀스는 데이터를 내보내거나 가져오는 순서를 제어하는 데 도움이 됩니다.

- 다른 실행 단위의 엔터티는 병렬로 처리됩니다.
- 각 실행 단위에서 개체의 수준이 같으면 병렬로 처리됩니다.
- 각 수준에서 엔터티는 해당 수준의 시퀀스 번호에 따라 처리됩니다.
- 한 레벨이 처리된 후 다음 레벨이 처리됩니다.

#### <a name="resequencing"></a>재배열
다음과 같은 상황에서 엔터티의 순서를 변경할 수 있습니다.

- 모든 변경 사항에 대해 하나의 데이터 작업만 사용되는 경우 순서 변경 옵션을 사용하여 전체 작업의 실행 시간을 최적화할 수 있습니다. 이러한 경우 실행 단위를 사용하여 모듈을 나타내고 레벨을 사용하여 모듈의 기능 영역을 나타내고 시퀀스를 사용하여 엔터티를 나타낼 수 있습니다. 이 접근 방식을 사용하면 여러 모듈에서 병렬로 작업할 수 있지만 여전히 모듈에서 순서대로 작업할 수 있습니다. 병렬 작업의 성공을 보장하려면 모든 종속성을 고려해야 합니다.
- 여러 데이터 작업이 사용되는 경우(예: 각 모듈에 대해 하나의 작업) 시퀀싱을 사용하여 최적의 실행을 위해 엔터티의 수준과 시퀀스에 영향을 줄 수 있습니다.
- 종속성이 전혀 없는 경우 최대 최적화를 위해 다른 실행 단위에서 엔터티를 시퀀싱할 수 있습니다.

**Resequencing** 메뉴는 여러 엔티티를 선택한 경우에 사용할 수 있습니다. 실행 단위, 레벨 또는 시퀀스 옵션을 기반으로 순서를 변경할 수 있습니다. 증분을 설정하여 선택한 엔티티의 순서를 변경할 수 있습니다. 각 엔티티에 대해 선택된 단위, 레벨 및/또는 시퀀스 번호는 지정된 증분만큼 업데이트됩니다.

#### <a name="sorting"></a>정렬,
**정렬 기준** 옵션을 사용하여 항목 목록을 순차적으로 볼 수 있습니다.

### <a name="truncating"></a>자르기
가져오기 프로젝트의 경우 가져오기 전에 엔터티의 기록을 자르도록 선택할 수 있습니다. 이것은 기록을 깨끗한 테이블 세트로 가져와야 하는 경우에 유용합니다. 이 설정은 기본적으로 꺼져 있습니다.

## <a name="validate-that-the-source-data-and-target-data-are-mapped-correctly"></a>원본 데이터와 대상 데이터가 올바르게 매핑되었는지 확인
매핑은 가져오기 및 내보내기 작업에 모두 적용되는 함수입니다.

- 가져오기 작업의 컨텍스트에서 매핑은 소스 파일의 어떤 열이 준비 테이블의 열이 되는지 설명합니다. 따라서 시스템은 소스 파일의 어떤 열 데이터를 준비 테이블의 어떤 열로 복사해야 하는지 결정할 수 있습니다.
- 내보내기 작업의 컨텍스트에서 매핑은 스테이징 테이블의 열(즉, 소스)이 대상 파일의 열이 되는 것을 설명합니다.

준비 테이블의 열 이름과 파일이 일치하는 경우 시스템은 이름을 기반으로 자동으로 매핑을 설정합니다. 그러나 이름이 다르면 열이 자동으로 매핑되지 않습니다. 이러한 경우 데이터 작업의 엔터티에서 **맵 보기** 옵션을 선택하여 매핑을 완료해야 합니다.

두 가지 매핑 보기가 있습니다. 기본 보기인 **매핑 시각화** 및 **매핑 세부 정보**. 빨간색 별표(\*)는 엔터티의 필수 필드를 나타냅니다. 엔터티로 작업하기 전에 이러한 필드를 매핑해야 합니다. 엔터티로 작업할 때 필요에 따라 다른 필드의 매핑을 해제할 수 있습니다. 필드 매핑을 해제하려면 **엔터티** 열이나 **소스** 열에서 필드를 선택한 다음 **선택 항목 삭제** 를 선택합니다. **저장** 을 선택하여 변경 사항을 저장한 다음 페이지를 닫고 프로젝트로 돌아갑니다. 가져온 후 동일한 프로세스를 사용하여 소스에서 스테이징으로 필드 매핑을 편집할 수 있습니다.

**소스 매핑 생성** 을 선택하여 페이지에서 매핑을 생성할 수 있습니다. 생성된 매핑은 자동 매핑처럼 작동합니다. 따라서 매핑되지 않은 필드를 수동으로 매핑해야 합니다.

![데이터 매핑.](./media/dixf-map.png)

## <a name="verify-the-security-for-your-import-or-export-job"></a>가져오기 또는 내보내기 작업의 보안 확인
관리자가 아닌 사용자가 특정 데이터 작업에만 액세스할 수 있도록 **데이터 관리** 작업 공간에 대한 액세스를 제한할 수 있습니다. 데이터 작업에 대한 액세스는 해당 작업의 실행 기록에 대한 전체 액세스 및 스테이징 테이블에 대한 액세스를 의미합니다. 따라서 데이터 작업을 생성할 때 적절한 액세스 제어가 있는지 확인해야 합니다.

### <a name="secure-a-job-by-roles-and-users"></a>역할 및 사용자별 작업 확보
**적용 가능한 역할** 메뉴를 사용하여 작업을 하나 이상의 보안 역할로 제한하십시오. 해당 역할의 사용자만 작업에 액세스할 수 있습니다.

특정 사용자로 작업을 제한할 수도 있습니다. 역할 대신 사용자별로 작업을 보호하면 여러 사용자가 역할에 할당되는 경우 더 많은 제어가 가능합니다.

### <a name="secure-a-job-by-legal-entity"></a>법인별 일자리 확보
데이터 작업은 본질적으로 글로벌합니다. 따라서 데이터 작업이 법인에서 생성되어 사용된 경우 해당 작업은 시스템의 다른 법인에서 볼 수 있습니다. 이 기본 동작은 일부 애플리케이션 시나리오에서 선호될 수 있습니다. 예를 들어 데이터 엔터티를 사용하여 송장을 가져오는 조직은 조직의 모든 부서에 대한 송장 오류 관리를 담당하는 중앙 집중식 송장 처리 팀을 제공할 수 있습니다. 이 시나리오에서는 중앙 집중식 송장 처리 팀이 모든 법인의 송장 가져오기 작업에 액세스하는 것이 유용합니다. 따라서 기본 동작은 법인 관점에서 요구 사항을 충족합니다.

그러나 조직은 법인별로 송장 처리 팀을 원할 수 있습니다. 이 경우 법인의 팀은 자체 법인의 송장 가져오기 작업에만 액세스할 수 있어야 합니다. 이 요구 사항을 충족하기 위해 데이터 작업 내의 **해당 법인** 메뉴를 사용하여 데이터 작업에 대한 법인 기반 액세스 제어를 구성할 수 있습니다. 구성이 완료되면 사용자는 현재 로그인한 법인에서 사용 가능한 작업만 볼 수 있습니다. 다른 법인의 작업을 보려면 사용자가 해당 법인으로 전환해야 합니다.

작업은 역할, 사용자 및 법인에 의해 동시에 보호될 수 있습니다.

## <a name="run-the-import-or-export-job"></a>가져오기 또는 내보내기 작업 실행
작업을 정의한 후 **가져오기** 또는 **내보내기** 버튼을 선택하여 작업을 한 번 실행할 수 있습니다. 반복 작업을 설정하려면 **반복 데이터 작업 만들기** 를 선택합니다.

> [!NOTE]
> 가져오기 또는 내보내기 버튼을 선택하여 **가져오기** 또는 **내보내기** 작업을 실행할 수 있습니다. 이렇게 하면 일괄 작업이 한 번만 실행되도록 예약됩니다. 일괄 서비스의 부하로 인해 일괄 서비스가 조절 중인 경우 작업이 즉시 실행되지 않을 수 있습니다. **지금 가져오기** 또는 **지금 내보내기** 를 선택하여 작업을 동기적으로 실행할 수도 있습니다. 이렇게 하면 작업이 즉시 시작되고 제한으로 인해 일괄 처리가 시작되지 않는 경우에 유용합니다. 작업은 나중에 실행되도록 예약할 수도 있습니다. 이 작업은 **일괄 실행** 옵션을 선택하여 수행할 수 있습니다. 일괄 리소스는 조절 대상이므로 일괄 작업이 즉시 시작되지 않을 수 있습니다. 일괄 처리를 사용하면 가져오거나 내보내야 하는 대용량 데이터에도 도움이 되기 때문에 권장되는 옵션입니다. 일괄 작업은 특정 일괄 그룹에서 실행되도록 예약할 수 있으므로 부하 분산 관점에서 더 많은 제어가 가능합니다.

## <a name="validate-that-the-job-ran-as-expected"></a>작업이 예상대로 실행되었는지 확인
작업 기록은 가져오기 및 내보내기 작업 모두에 대한 문제 해결 및 조사에 사용할 수 있습니다. 기록 작업 실행은 시간 범위별로 구성됩니다.

![작업 기록 범위.](./media/dixf-job-history.md.png)

각 작업 실행은 다음 세부 정보를 제공합니다.

- 실행 세부정보
- 실행 로그

실행 세부 정보는 작업이 처리한 각 데이터 엔터티의 상태를 보여줍니다. 따라서 다음 정보를 빠르게 찾을 수 있습니다.

- 어떤 엔터티가 처리되었습니다.
- 엔터티의 경우 성공적으로 처리된 기록 수와 실패한 기록 수입니다.
- 각 엔터티에 대한 준비 기록입니다.

내보내기 작업을 위해 스테이징 데이터를 파일로 다운로드하거나 가져오기 및 내보내기 작업을 위한 패키지로 다운로드할 수 있습니다.

실행 세부 정보에서 실행 로그를 열 수도 있습니다.

## <a name="parallel-imports"></a>병렬 가져오기
엔티티가 병렬 가져오기를 지원하는 경우 데이터 가져오기의 속도를 높이기 위해 파일 가져오기의 병렬 처리를 활성화할 수 있습니다. 엔터티에 대한 병렬 가져오기를 구성하려면 다음 단계를 따라야 합니다.

1. **시스템 관리 \> 작업 공간 \> 데이터 관리** 로 이동합니다.
2. **가져오기/내보내기** 섹션에서 **프레임워크 매개 변수** 타일을 선택하여 **데이터 가져오기/내보내기 프레임워크 매개 변수** 페이지를 엽니다.
3. **엔터티 설정** 탭에서 **엔터티 실행 매개 변수 구성** 을 선택하여 **엔터티 가져오기 실행 매개 변수** 페이지를 엽니다.
4. 엔터티에 대한 병렬 가져오기를 구성하려면 다음 필드를 설정합니다.

    - **엔터티** 필드에서 엔터티를 선택합니다.
    - **임계값 기록 수 가져오기** 필드에 가져올 임계값 기록 수를 입력합니다. 스레드에서 처리할 기록 수를 결정합니다. 파일에 10K 기록이 있는 경우 작업 수가 4이고 기록 수가 2500이면 각 스레드가 2500개의 기록을 처리합니다.
    - **가져오기 작업 수** 필드에 가져오기 작업 수를 입력합니다. 이는 **시스템 관리 \> 서버 구성** 에서 일괄 처리에 할당된 최대 일괄 스레드를 초과하지 않아야 합니다.

## <a name="job-history-clean-up"></a>작업 기록 정리 
데이터 관리의 작업 기록 정리 함수은 실행 기록의 주기적인 정리를 예약하는 데 사용해야 합니다. 이 함수은 더 이상 사용되지 않는 이전 스테이징 테이블 정리 함수를 대체합니다. 다음 표는 정리 프로세스에 의해 정리됩니다.

-   모든 준비 테이블

-   DMFS스테이징검증로그

-   DMFSTAGING실행 오류

-   DMFSTAGINGLOGDETAIL

-   DMFSTAGING로그

-   DMFDEFINITIONGROUP실행 기록

-   DMF실행

-   DMFDEFINITION그룹실행

**실행 기록 정리** 기능은 기능 관리에서 활성화되어야 하며 **데이터 관리 \> 작업 기록 정리** 에서 액세스할 수 있습니다.

### <a name="scheduling-parameters"></a>스케줄링 매개 변수

정리 프로세스를 예약할 때 정리 기준을 정의하려면 다음 매개 변수를 지정해야 합니다.

-   **기록을 보존할 일 수** – 이 설정은 보존할 실행 기록의 양을 제어하는 데 사용됩니다. 이것은 일수로 지정됩니다. 정리 작업이 반복되는 배치 작업으로 예약된 경우 이 설정은 계속 이동하는 창처럼 작동하여 나머지는 삭제하는 동안 지정된 날짜 수 동안의 기록은 항상 그대로 유지합니다. 기본값은 7일입니다.

-   **작업 실행 시간** – 정리할 기록의 양에 따라 정리 작업의 총 실행 시간은 몇 분에서 몇 시간까지 다양할 수 있습니다. 이 매개 변수는 작업을 실행할 시간으로 설정해야 합니다. 정리 작업이 지정된 시간 동안 실행되면 작업이 종료되고 반복 일정에 따라 다음에 실행할 때 정리를 다시 시작합니다.

    이 설정을 사용하여 작업을 실행해야 하는 시간에 대한 최대 제한을 설정하여 최대 실행 시간을 지정할 수 있습니다. 정리 논리는 시간순으로 정렬된 순서로 한 번에 하나의 작업 실행 ID를 거치며 가장 오래된 것이 관련 실행 기록 정리를 위해 먼저 처리됩니다. 남은 실행 기간이 지정된 기간의 마지막 10% 이내이면 정리를 위해 새 실행 ID 선택을 중지합니다. 경우에 따라 정리 작업이 지정된 최대 시간을 초과하여 계속될 것으로 예상됩니다. 이는 10% 임계값에 도달하기 전에 시작된 현재 실행 ID에 대해 삭제할 기록 수에 따라 크게 달라집니다. 시작된 정리는 데이터 무결성을 보장하기 위해 완료되어야 합니다. 즉, 지정된 제한을 초과하더라도 정리가 계속됩니다. 이 작업이 완료되면 새 실행 ID가 선택되지 않고 정리 작업이 완료됩니다. 실행 시간이 부족하여 정리되지 않은 나머지 실행 기록은 다음 정리 작업이 예약될 때 선택됩니다. 이 설정의 기본값 및 최소값은 2시간으로 설정됩니다.

-   **반복 배치** – 정리 작업은 일회성 수동 실행으로 실행하거나 배치로 반복 실행되도록 예약할 수도 있습니다. 표준 배치 설정인 **백그라운드에서 실행** 설정을 사용하여 배치를 예약할 수 있습니다.

> [!NOTE]
> 준비 테이블의 기록이 완전히 정리되지 않은 경우 정리 작업이 반복 실행되도록 예약되어 있는지 확인하십시오. 위에서 설명한 대로 정리 실행에서 작업은 제공된 최대 시간 내에 가능한 한 많은 실행 ID만 정리합니다. 나머지 준비 기록을 계속 정리하려면 작업이 주기적으로 실행되도록 예약해야 합니다.

## <a name="job-history-clean-up-and-archival"></a>작업 기록 정리 및 보관 
작업 기록 정리 및 보관 함수은 정리 함수의 이전 버전을 대체합니다. 이 섹션에서는 이러한 새로운 기능에 대해 설명합니다.

정리 함수의 주요 변경 사항 중 하나는 기록 정리를 위해 시스템 일괄 작업을 사용하는 것입니다. 시스템 배치 작업을 사용하면 재무 및 운영 앱이 정리 배치 작업을 자동으로 예약하고 시스템이 준비되는 즉시 실행할 수 있습니다. 더 이상 배치 작업을 수동으로 예약할 필요가 없습니다. 이 기본 실행 모드에서 일괄 작업은 자정부터 매시간 실행되며 가장 최근 7일 동안의 실행 기록을 유지합니다. 제거된 기록은 나중에 검색할 수 있도록 보관됩니다. 버전 10.0.20부터 이 기능은 항상 켜져 있습니다.

정리 프로세스의 두 번째 변경 사항은 제거된 실행 기록의 보관입니다. 정리 작업은 삭제된 기록을 DIXF가 일반 통합에 사용하는 Blob Storage에 보관합니다. 보관된 파일은 DIXF 패키지 형식이며 Blob에서 7일 동안 사용할 수 있으며 이 기간 동안 다운로드할 수 있습니다. 아카이브된 파일의 기본 수명인 7일을 매개 변수에서 최대 90일로 변경할 수 있습니다.

### <a name="changing-the-default-settings"></a>기본 설정 변경
이 함수은 현재 미리 보기 상태이며 플라이트 DMFEnableExecutionHistoryCleanupSystemJob을 활성화하여 명시적으로 켜야 합니다. 기능 관리에서 스테이징 정리 기능도 켜야 합니다.

보관된 파일의 수명에 대한 기본 설정을 변경하려면 데이터 관리 작업 공간으로 이동하여 **작업 기록 정리** 를 선택합니다. **Blob에 패키지를 보관할 일수** 를 7에서 90(포함) 사이의 값으로 설정합니다. 이 변경 사항이 적용된 후 생성된 아카이브에 적용됩니다.

### <a name="downloading-the-archived-package"></a>보관된 패키지 다운로드
이 함수은 현재 미리 보기 상태이며 플라이트 DMFEnableExecutionHistoryCleanupSystemJob을 활성화하여 명시적으로 켜야 합니다. 기능 관리에서 스테이징 정리 기능도 켜야 합니다.

보관된 실행 기록을 다운로드하려면 데이터 관리 작업 공간으로 이동하여 **작업 기록 정리** 를 선택합니다. **패키지 백업 기록** 을 선택하여 기록 양식을 엽니다. 이 양식은 보관된 모든 패키지 목록을 보여줍니다. **패키지 다운로드** 를 선택하여 아카이브를 선택하고 다운로드할 수 있습니다. 다운로드한 패키지는 DIXF 패키지 형식이며 다음 파일을 포함합니다.

-   엔티티 스테이징 테이블 파일
-   DMFDEFINITION그룹실행
-   DMFDEFINITIONGROUP실행 기록
-   DMF실행
-   DMFSTAGING실행 오류
-   DMFSTAGING로그
-   DMFS스테이징로그세부정보
-   DMFS스테이징검증로그



[!INCLUDE[footer-include](../../../includes/footer-banner.md)]
